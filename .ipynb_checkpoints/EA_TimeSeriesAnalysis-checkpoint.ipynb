{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef65c089-232a-44e5-87fe-f5197bf255e7",
   "metadata": {},
   "source": [
    "# Environment Agency Real Time flood-monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977301b5-9b30-4ba7-9c3e-49b97ffe36f3",
   "metadata": {},
   "source": [
    "## Management summary for this file\n",
    "\n",
    "### Purpose: Time series analysis and prediction\n",
    "This notebook uses Environment Agency data for a single monitoring station previously selected using the map in an associated tool EA_Flood.ipynb\n",
    "\n",
    "Data is readily available for the past 12 months for all 6279 measuring instruments at 5391 monitoring stations across England. All this data has been persisted to a local PostgreSQL database to reduce internet traffic whilst developing this project. The csv file containing data for one instrument used this assignment has been extracted from that local database.  \n",
    "\n",
    "Measurments from the Agency's flood-monitoring instruments are most commonly taken every 15 minutes but where changes are rapid, or where they critcal to the flood monitoring programme, measurements may be taken more frequently.  The station we are investigating here sits on the south bank of the River Severn in Gloucestershire, a river famous for having the second biggest tidal range in the world, at peak around 15 metres. This station collects data every 5 minutes and so for the year from March 2024 we have some 92,000 data points (from 170 million data points dowloaded for all stations in England). A rich dataset to work with.\n",
    "\n",
    "### Support: API docs\n",
    "Full API documentation can be found at \"http://environment.data.gov.uk/flood-monitoring/doc/reference\"\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e2245d-e4a4-4225-b622-45d9602173b3",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bddaddc-2df0-4986-ab65-1b24433325e0",
   "metadata": {},
   "source": [
    "### Set programme directives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ff2a78e-4bbf-4daf-b45a-073a24aecf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program directives\n",
    "\n",
    "# Load data from local database or csv file (for small offshoot projects)\n",
    "LOAD_FROM_CSV = False\n",
    "TRAIN_MODEL = False   # can be time consuming. comment out if you're working on say presenation\n",
    "MODEL_USING_SMOOTHED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5871e60-2af9-4ff9-a049-81ac0735cbbd",
   "metadata": {},
   "source": [
    "### Install libraries \n",
    "(Set \"INSTALL=True\" to switch on once only, otherwise set \"INSTALL=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c0c2754-3358-4184-bb74-c6a6be7b28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTALL=False\n",
    "if INSTALL:\n",
    "    !pip install requests\n",
    "    !pip install sqlalchemy\n",
    "    !pip install gdal\n",
    "    !pip install selenium pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704cf7e8-a242-4b2e-b68a-9e07e0cb7d2a",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7426c8ee-45e8-4813-8264-5360d09ac4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# the key players\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# other general purpose libraries\n",
    "import csv\n",
    "import datetime \n",
    "from datetime import timedelta\n",
    "\n",
    "# for database connectivity\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "\n",
    "# for interactive Bokeh plots\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import ColumnDataSource, Button, CustomJS, DateRangeSlider, DatetimeTickFormatter, HoverTool, Range1d\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.io.export import export_png\n",
    "#from bokeh.io.export import export_pdf\n",
    "\n",
    "# for machine learning\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e647a-1110-49d6-984f-ffebc563ae63",
   "metadata": {},
   "source": [
    "### Set display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f515ab-58d3-4eac-9178-c5260d889c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display all columns and rows:\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "# to set display width (for auto text wrapping)\n",
    "pd.set_option('display.width', 180)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "# set float number format to 2dp\n",
    "#pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# force dataframes to not wrap across lines\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0d7f8-ecba-4d97-ac06-2483322df6da",
   "metadata": {},
   "source": [
    "## Working with the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eeb1a6-09ec-4b51-a394-b8073da4eab4",
   "metadata": {},
   "source": [
    "### Connection details for Postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1fb5f56-6f72-4f6a-905b-e3f6d72c43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SQLAlchemy engine (aka a connection to the postgresql database) - this is required for pandas connections\n",
    "if not LOAD_FROM_CSV:\n",
    "    db_username = 'postgres'\n",
    "    db_password = 'postgres'\n",
    "    db_hostname = '192.168.101.12'\n",
    "    db_port     = '5432'\n",
    "    db_schema   = 'envagency'\n",
    "    \n",
    "    engine = create_engine(f'postgresql+psycopg2://{db_username}:{db_password}@{db_hostname}:{db_port}/{db_schema}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b57dae-f9f5-4de0-aa2c-ad2e238f08a0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac96c5-0aa7-4141-8939-0e9936666adc",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a9c2943-54d6-4f27-8bd7-6df12b30cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end datetime for the range\n",
    "start_datetime = '2024-04-02 00:00:00'\n",
    "end_datetime   = '2025-03-31 00:00:00'\n",
    "\n",
    "# The \"station reference\" identifier for the Environment Agency measuring instrument (eg water level gauge) \n",
    "stationReference = '2195'\n",
    "\n",
    "if LOAD_FROM_CSV:\n",
    "    df = pd.read_csv('EA_limited_dataset.csv')\n",
    "else:\n",
    "    query = f'''\n",
    "            select * from readings where stationReference = '{stationReference}'\n",
    "            and r_datetime between '{start_datetime}' AND '{end_datetime}'\n",
    "            ''' \n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    \n",
    "    # If we are collecting this data from the datebase, lets save it to csv for \n",
    "    # portability to be used where access to this local database is restricted ro unavailable.\n",
    "    df.to_csv('EA_limited_dataset.csv', index=False)  # index=False prevents writing row indices\n",
    "\n",
    "# inspect the DataFrame\n",
    "#print(df)\n",
    "\n",
    "# Ensure the timeseries date column is correct for pandas\n",
    "#df['r_datetime'] = pd.to_datetime(df['r_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e69306a-73dd-4692-8acd-43b233b90ce4",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d2282-7ece-4829-b068-5c7e270d7094",
   "metadata": {},
   "source": [
    "## Creating an interactive time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1c812d3-2e21-4a2b-b4f6-0b9e355dda72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"a3c7290b-2491-4bf0-af05-48269d01af55\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "'use strict';\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded(error = null) {\n",
       "    const el = document.getElementById(\"a3c7290b-2491-4bf0-af05-48269d01af55\");\n",
       "    if (el != null) {\n",
       "      const html = (() => {\n",
       "        if (typeof root.Bokeh === \"undefined\") {\n",
       "          if (error == null) {\n",
       "            return \"BokehJS is loading ...\";\n",
       "          } else {\n",
       "            return \"BokehJS failed to load.\";\n",
       "          }\n",
       "        } else {\n",
       "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
       "          if (error == null) {\n",
       "            return `${prefix} successfully loaded.`;\n",
       "          } else {\n",
       "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
       "          }\n",
       "        }\n",
       "      })();\n",
       "      el.innerHTML = html;\n",
       "\n",
       "      if (error != null) {\n",
       "        const wrapper = document.createElement(\"div\");\n",
       "        wrapper.style.overflow = \"auto\";\n",
       "        wrapper.style.height = \"5em\";\n",
       "        wrapper.style.resize = \"vertical\";\n",
       "        const content = document.createElement(\"div\");\n",
       "        content.style.fontFamily = \"monospace\";\n",
       "        content.style.whiteSpace = \"pre-wrap\";\n",
       "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
       "        content.textContent = error.stack ?? error.toString();\n",
       "        wrapper.append(content);\n",
       "        el.append(wrapper);\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(() => display_loaded(error), 100);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.6.0.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      try {\n",
       "            for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "\n",
       "      } catch (error) {display_loaded(error);throw error;\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"a3c7290b-2491-4bf0-af05-48269d01af55\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"a3c7290b-2491-4bf0-af05-48269d01af55\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.6.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"a3c7290b-2491-4bf0-af05-48269d01af55\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()\n",
    "\n",
    "def createTimeplot  (df, \n",
    "                     show_predicted = False,\n",
    "                     future_predictions = None,\n",
    "                     future_steps   = 48,\n",
    "                     publishPlot    = False, \n",
    "                     plotName       =\"SharpnessWaterLevelPlot.html\"\n",
    "                    ):\n",
    "    '''\n",
    "    Purpose:  Create an interactive timeseries chart, showing raw, smoothed, cleaned continuous data, and also identifying spikes and flatlining in the dataset\n",
    "    Params:   The timeseries dataframe comprising a date/time column and a single value\n",
    "    Returns:  A Bokeh plot object\n",
    "    '''\n",
    "    print(df)\n",
    "    # Ensure the timeseries date column is correct for pandas\n",
    "    df['r_datetime'] = pd.to_datetime(df['r_datetime'])\n",
    "    \n",
    "    # Sort the dataset by time\n",
    "    df = df.sort_values('r_datetime')\n",
    "    \n",
    "    # Create a new column for a rolling average to smooth the 'value' column\n",
    "    # Our data points are every 5 minutes, so window=24 invokes 2 hour smoothing\n",
    "    df['value_smooth'] = df['value'].rolling(window=24, center=True).mean()\n",
    "    \n",
    "    \n",
    "    # =======================\n",
    "    # An independent inquiry into cleaning data: \n",
    "    # =======================\n",
    "    # Create column 'diff' - the absolute difference between this reading and the previous reading\n",
    "    df['diff'] = df['value'].diff().abs()\n",
    "    # Calculate a threshold based on 3x standard deviations from the mean of 'diff'\n",
    "    threshold = df['diff'].mean() + 3 * df['diff'].std()\n",
    "    # Create column 'spike' to identify values of 'diff' greater than the threshold\n",
    "    df['spike'] = df['diff'] > threshold\n",
    "    # Create column 'flat' to identify values of 'diff' that are very small or 0 (flatlining)\n",
    "    df['flat'] = df['diff'] < 0.02\n",
    "    # Create a df of spike events for plotting\n",
    "    spike_source = ColumnDataSource(df[df['spike'] | df['flat']])\n",
    "    \n",
    "    # Create a column 'value_clean' set to the same as the original 'value' column\n",
    "    df['value_clean'] = df['value']\n",
    "    # Set 'value_clean' to NaN where a spike has been detected\n",
    "    df.loc[df['spike'] == True, 'value_clean'] = np.nan\n",
    "    # Set 'value_clean' to NaN where flatlining has been detected\n",
    "    df.loc[df['flat']  == True, 'value_clean'] = np.nan\n",
    "    #print(df[['r_datetime'] + df.columns[-6:].tolist()])\n",
    "        \n",
    "    # Set 'value_clean' to an interpolated value for these NaNs (first, set an index to support interpolation)\n",
    "    df.set_index('r_datetime', inplace=True)\n",
    "    df['value_clean'] = df['value_clean'].interpolate(method='time')\n",
    "    df.reset_index(inplace=True)\n",
    "    #print(df[['r_datetime'] + df.columns[-6:].tolist()])\n",
    "    # =======================\n",
    "\n",
    "    # Set up data\n",
    "    source = ColumnDataSource(df)\n",
    "    start_date = df['r_datetime'].min()\n",
    "    end_date   = df['r_datetime'].max()\n",
    "    \n",
    "    # Define fixed y range (this will not be \"pannable\")\n",
    "    y_min = df['value'].min()\n",
    "    y_max = df['value'].max()\n",
    "    \n",
    "    # Create figure\n",
    "    p = figure(\n",
    "        x_axis_type=\"datetime\",\n",
    "        title=\"Water level at Sharpness (River Severn)\",\n",
    "        sizing_mode=\"stretch_width\",  # auto width\n",
    "        height=400,                   # keep height\n",
    "        min_width=900,\n",
    "        tools=\"xpan,wheel_zoom,box_zoom,reset\",   #note: pan allows for panning in both axes \n",
    "        #x_range=Range1d(start=start_date, end=end_date),\n",
    "        x_range=Range1d(start=end_date - timedelta(days=30), end=end_date),\n",
    "        y_range=Range1d(start=y_min, end=y_max),\n",
    "        active_inspect=None  # Disable default inspect tools like hover\n",
    "    )\n",
    "    \n",
    "    #p.line(x='r_datetime', y='value', source=source, line_width=2, color=\"blue\")\n",
    "    p.line(x='r_datetime', y='value', source=source, line_width=1, color=\"gray\", alpha=0.5, legend_label=\"Raw\")\n",
    "    p.line(x='r_datetime', y='value_smooth', source=source, line_width=2, color=\"blue\", legend_label=\"Smoothed\")\n",
    "    p.scatter(x='r_datetime', y='value', source=spike_source, size=6, color=\"red\", legend_label=\"Spikes\")\n",
    "    p.line(x='r_datetime', y='value_clean', source=source, line_width=2, color=\"pink\", legend_label=\"Cleaned\")\n",
    "    \n",
    "    if show_predicted:\n",
    "        # Create future timestamps starting right after the last datetime in df\n",
    "        future_index = pd.date_range(\n",
    "            start=df['r_datetime'].max() + pd.Timedelta(minutes=5),\n",
    "            periods=future_steps,\n",
    "            freq='5min'\n",
    "        )\n",
    "        \n",
    "        # a df for future predictions\n",
    "        future_df = pd.DataFrame({\n",
    "            'r_datetime': future_index,\n",
    "            'value'       : pd.Series([np.nan] * future_steps, dtype='float64'),\n",
    "            'value_smooth': pd.Series([np.nan] * future_steps, dtype='float64'),\n",
    "            'value_clean' : pd.Series([np.nan] * future_steps, dtype='float64'),\n",
    "            'predicted'   : future_predictions.flatten()\n",
    "        })\n",
    "        \n",
    "        # add the future prediction to the end of the existign df\n",
    "        df_extended = pd.concat([df, future_df], ignore_index=True)\n",
    "        \n",
    "        source = ColumnDataSource(df_extended)\n",
    "        p.line(\n",
    "            x='r_datetime',\n",
    "            y='predicted',\n",
    "            source=source,\n",
    "            line_width=2,\n",
    "            color=\"green\",\n",
    "            legend_label=\"Predicted\"\n",
    "        )\n",
    "\n",
    "        # set a new end date for the plot\n",
    "        end_date = df_extended['r_datetime'].max()\n",
    "\n",
    "    \n",
    "    p.xaxis.formatter = DatetimeTickFormatter(days=\"%b %d\", months=\"%b %Y\", hours=\"%H:%M\", minutes=\"%H:%M\")\n",
    "    \n",
    "    # Enable interactive legend\n",
    "    p.legend.click_policy = \"hide\"  # or \"mute\" for faded style\n",
    "    p.legend.location = \"top_left\"  \n",
    "    \n",
    "    hover = HoverTool(\n",
    "        tooltips=[(\"Date\", \"@r_datetime{%F %T}\"), (\"Value\", \"@value\")],\n",
    "        formatters={\"@r_datetime\": \"datetime\"},\n",
    "        mode='vline'\n",
    "    )\n",
    "    p.add_tools(hover)\n",
    "    \n",
    "    # Date range slider\n",
    "    date_range_slider = DateRangeSlider(\n",
    "        title=\"Select Date Range:\",\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        #start=df['r_datetime'].min(),\n",
    "        #end=df['r_datetime'].max(),\n",
    "        #value=(df['r_datetime'].min(), df['r_datetime'].max()),\n",
    "        value=(df['r_datetime'].max() - timedelta(days=30), df['r_datetime'].max()),\n",
    "        step=1,\n",
    "        width=900\n",
    "    )\n",
    "    \n",
    "    # Link slider to x_range of the plot\n",
    "    callback = CustomJS(args=dict(p=p, slider=date_range_slider), code=\"\"\"\n",
    "        p.x_range.start = slider.value[0];\n",
    "        p.x_range.end = slider.value[1];\n",
    "    \"\"\")\n",
    "    date_range_slider.js_on_change(\"value\", callback)\n",
    "    \n",
    "    # Buttons\n",
    "    button_7d = Button(label=\"Last 7 Days\", width=100)\n",
    "    button_30d = Button(label=\"Last 30 Days\", width=100)\n",
    "    button_90d = Button(label=\"Last 90 Days\", width=100)\n",
    "    button_all = Button(label=\"All Time\", width=100)\n",
    "    \n",
    "    button_7d_view = Button(label=\"7 Day View\", width=100)\n",
    "    button_30d_view = Button(label=\"30 Day View\", width=100)\n",
    "    button_90d_view = Button(label=\"90 Day View\", width=100)\n",
    "    \n",
    "    # JS callbacks\n",
    "    button_7d_view.js_on_click(CustomJS(args=dict(p=p, slider=date_range_slider), code=f\"\"\"\n",
    "        const start = p.x_range.start;\n",
    "        const end = p.x_range.end;\n",
    "        const hardEnd = new Date(\"{end_date.isoformat()}\").getTime();\n",
    "        const span = 3.5 * 24 * 60 * 60 * 1000;  // half of 7 days in ms\n",
    "        const center = Math.min((start + end) / 2, hardEnd - span);\n",
    "        p.x_range.start = center - span;\n",
    "        p.x_range.end = center + span;\n",
    "        slider.value = [p.x_range.start, p.x_range.end];\n",
    "    \"\"\"))\n",
    "    \n",
    "    button_30d_view.js_on_click(CustomJS(args=dict(p=p, slider=date_range_slider), code=f\"\"\"\n",
    "        const start = p.x_range.start;\n",
    "        const end = p.x_range.end;\n",
    "        const hardEnd = new Date(\"{end_date.isoformat()}\").getTime();\n",
    "        const span = 15 * 24 * 60 * 60 * 1000;  // half of 7 days in ms\n",
    "        const center = Math.min((start + end) / 2, hardEnd - span);\n",
    "        p.x_range.start = center - span;\n",
    "        p.x_range.end = center + span;\n",
    "        slider.value = [p.x_range.start, p.x_range.end];\n",
    "    \"\"\"))\n",
    "    \n",
    "    button_90d_view.js_on_click(CustomJS(args=dict(p=p, slider=date_range_slider), code=f\"\"\"\n",
    "        const start = p.x_range.start;\n",
    "        const end = p.x_range.end;\n",
    "        const hardEnd = new Date(\"{end_date.isoformat()}\").getTime();\n",
    "        const span = 45 * 24 * 60 * 60 * 1000;  // half of 7 days in ms\n",
    "        const center = Math.min((start + end) / 2, hardEnd - span);\n",
    "        p.x_range.start = center - span;\n",
    "        p.x_range.end = center + span;\n",
    "        slider.value = [p.x_range.start, p.x_range.end];\n",
    "    \"\"\"))\n",
    "    \n",
    "    button_7d.js_on_click(CustomJS(args=dict(p=p, slider=date_range_slider), code=f\"\"\"\n",
    "        const end = new Date(\"{end_date.isoformat()}\").getTime();\n",
    "        const start = end - 7*24*60*60*1000;\n",
    "        p.x_range.start = start;\n",
    "        p.x_range.end = end;\n",
    "        slider.value = [start, end];\n",
    "    \"\"\"))\n",
    "    \n",
    "    button_30d.js_on_click(CustomJS(args=dict(p=p, slider=date_range_slider), code=f\"\"\"\n",
    "        const end = new Date(\"{end_date.isoformat()}\").getTime();\n",
    "        const start = end - 30*24*60*60*1000;\n",
    "        p.x_range.start = start;\n",
    "        p.x_range.end = end;\n",
    "        slider.value = [start, end];\n",
    "    \"\"\"))\n",
    "    \n",
    "    button_90d.js_on_click(CustomJS(args=dict(p=p, slider=date_range_slider), code=f\"\"\"\n",
    "        const end = new Date(\"{end_date.isoformat()}\").getTime();\n",
    "        const start = end - 90*24*60*60*1000;\n",
    "        p.x_range.start = start;\n",
    "        p.x_range.end = end;\n",
    "        slider.value = [start, end];\n",
    "    \"\"\"))\n",
    "    \n",
    "    button_all.js_on_click(CustomJS(args=dict(p=p, slider=date_range_slider), code=f\"\"\"\n",
    "        const start = new Date(\"{start_date.isoformat()}\").getTime();\n",
    "        const end = new Date(\"{end_date.isoformat()}\").getTime();\n",
    "        p.x_range.start = start;\n",
    "        p.x_range.end = end;\n",
    "        slider.value = [start, end];\n",
    "    \"\"\"))\n",
    "    \n",
    "    # The following line:\n",
    "    #   1) saves the ts plot html file to the current directory. This can be pushed from git to \"github pages\" to be published as a simple web page\n",
    "    #   2) automagically show the plot in a browser window as this notebook runs\n",
    "    if publishPlot:\n",
    "        output_file(plotName)  # Generates an HTML file in the current directory\n",
    "    \n",
    "    # Show layout in this notebook\n",
    "    #show(column(p, date_range_slider, row(button_7d_view, button_30d_view, button_90d_view), row(button_7d, button_30d, button_90d, button_all)))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb3b7ab6-1631-4a21-8087-fe18cb3d845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          created        source                r_datetime      r_date                                           measure                  station label stationreference parameter qualifier                 datumtype  period unitname      valuetype  value\n",
      "0      2025-04-03 14:49:00.652109  EA2024-04-02 2024-04-02 00:00:00+00:00  2024-04-02  {root}/id/measures/2195-level-stage-i-5_min-mASD  {root}/id/stations/2195  None             2195     level     Stage  {root}/def/core/datumASD     300     mASD  instantaneous   5.91\n",
      "1      2025-04-03 14:49:00.652109  EA2024-04-02 2024-04-02 00:15:00+00:00  2024-04-02  {root}/id/measures/2195-level-stage-i-5_min-mASD  {root}/id/stations/2195  None             2195     level     Stage  {root}/def/core/datumASD     300     mASD  instantaneous   5.70\n",
      "2      2025-04-03 14:49:00.652109  EA2024-04-02 2024-04-02 00:10:00+00:00  2024-04-02  {root}/id/measures/2195-level-stage-i-5_min-mASD  {root}/id/stations/2195  None             2195     level     Stage  {root}/def/core/datumASD     300     mASD  instantaneous   5.77\n",
      "3      2025-04-03 14:49:00.652109  EA2024-04-02 2024-04-02 00:05:00+00:00  2024-04-02  {root}/id/measures/2195-level-stage-i-5_min-mASD  {root}/id/stations/2195  None             2195     level     Stage  {root}/def/core/datumASD     300     mASD  instantaneous   5.84\n",
      "4      2025-04-03 14:49:00.652109  EA2024-04-02 2024-04-02 00:30:00+00:00  2024-04-02  {root}/id/measures/2195-level-stage-i-5_min-mASD  {root}/id/stations/2195  None             2195     level     Stage  {root}/def/core/datumASD     300     mASD  instantaneous   5.42\n",
      "...                           ...           ...                       ...         ...                                               ...                      ...   ...              ...       ...       ...                       ...     ...      ...            ...    ...\n",
      "102731 2025-04-05 13:07:41.711584  EA2025-03-30 2025-03-30 15:05:00+00:00  2025-03-30  {root}/id/measures/2195-level-stage-i-5_min-mASD  {root}/id/stations/2195  None             2195     level     Stage  {root}/def/core/datumASD     300     mASD  instantaneous   0.99\n",
      "102732 2025-04-05 13:07:41.681388  EA2025-03-30 2025-03-30 12:10:00+00:00  2025-03-30  {root}/id/measures/2195-level-stage-i-5_min-mASD  {root}/id/stations/2195  None             2195     level     Stage  {root}/def/core/datumASD     300     mASD  instantaneous   3.02\n",
      "102733 2025-04-05 13:07:41.683430  EA2025-03-30 2025-03-30 14:00:00+00:00  2025-03-30  {root}/id/measures/2195-level-stage-i-5_min-mASD  {root}/id/stations/2195  None             2195     level     Stage  {root}/def/core/datumASD     300     mASD  instantaneous   1.58\n",
      "102734 2025-04-05 13:07:41.691459  EA2025-03-30 2025-03-30 05:25:00+00:00  2025-03-30  {root}/id/measures/2195-level-stage-i-5_min-mASD  {root}/id/stations/2195  None             2195     level     Stage  {root}/def/core/datumASD     300     mASD  instantaneous   0.56\n",
      "102735 2025-04-05 13:08:25.393584  EA2025-03-31 2025-03-31 00:00:00+00:00  2025-03-31  {root}/id/measures/2195-level-stage-i-5_min-mASD  {root}/id/stations/2195  None             2195     level     Stage  {root}/def/core/datumASD     300     mASD  instantaneous   3.51\n",
      "\n",
      "[102736 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def createTimeplot  (df, \n",
    "                     show_predicted = False,\n",
    "                     future_predictions = None,\n",
    "                     future_steps   = 48,\n",
    "                     publishPlot    = False, \n",
    "                     plotName       =\"SharpnessWaterLevelPlot.html\"\n",
    "                    ):\n",
    "'''\n",
    "createTimeplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b894714d-68e3-4190-82e9-4eba0e542c22",
   "metadata": {},
   "source": [
    "## Creating an LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5044c38b-501e-47b3-89ff-78bd5a293b7e",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f15d4671-e9c9-4e15-9c5b-c1e0c280da77",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['value_clean'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     days_to_predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     data \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_clean\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     14\u001b[0m     days_to_predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Normalize - transforms the data to range 0 to 1\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ARU-Dev\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ARU-Dev\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ARU-Dev\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['value_clean'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "\n",
    "# Make sure datetime is sorted (we did this earlier but it doesn't hurt to repeat this in case this cell is run standalone)\n",
    "df = df.sort_values('r_datetime')\n",
    "\n",
    "# Set r_datetime as the index before extracting the 'value_smooth' column\n",
    "df.set_index('r_datetime', inplace=True)\n",
    "\n",
    "# Use the smoothed value for demostarting how awful it is.  The cleaned data is much better\n",
    "# You could add the raw data into the mix here\n",
    "if MODEL_USING_SMOOTHED:\n",
    "    data = df[['value_smooth']].dropna().values  # Drop NaNs if smoothing used\n",
    "    days_to_predict = 1\n",
    "else:\n",
    "    data = df[['value_clean']]\n",
    "    days_to_predict = 7\n",
    "\n",
    "\n",
    "# Normalize - transforms the data to range 0 to 1\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Define sequence length\n",
    "seq_len = 48  # past 4 hours if 5-min intervals\n",
    "X, y = [], []\n",
    "\n",
    "for i in range(seq_len, len(data_scaled)):\n",
    "    X.append(data_scaled[i-seq_len:i])\n",
    "    y.append(data_scaled[i])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Reshape for LSTM\n",
    "print(\"X shape:\", X.shape)  # (samples, timesteps, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b86595-4808-459a-95b3-899b5ac1a6b2",
   "metadata": {},
   "source": [
    "### Create the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc2c17-a659-45bc-b1ed-71d82cf06919",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(X.shape[1], X.shape[2])),  # Shape: (timesteps, features)\n",
    "    # First LSTM layer with dropout to prevent overfitting\n",
    "    LSTM(units=64, return_sequences=True ),  # passes full sequences on to the next layer\n",
    "    LSTM(units=64, return_sequences=False),  # passes final hidden state to the output (dense) layer\n",
    "    Dense(units=1)  # Output layer - this is the prediction of the next value\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Hyperparameter tuning: The configuration of the model is worthy of further investigation, specifically \n",
    "#   * number of layers\n",
    "#   * number of units in each layer\n",
    "#   * epochs  (see fit in next cell)\n",
    "#   * batch size  (see fit in next cell)\n",
    "\n",
    "# Evaluation: Try other metrics to determine performance\n",
    "#   * MAE (mean absolute error)\n",
    "#   * RSME (root mean squared error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb2401-6dd8-4519-823e-e9b3b00a7e68",
   "metadata": {},
   "source": [
    "### Train the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca19dce-290d-4103-9e86-94c2aff5e6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',        # what to monitor (usually 'val_loss' or 'loss')\n",
    "    patience=10,               # how many epochs to wait before stopping\n",
    "    restore_best_weights=True  # restore the best weights at the end\n",
    ")\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, callbacks=[early_stopping], validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b410a8fc-0bb7-402a-888a-5ff1c084714c",
   "metadata": {},
   "source": [
    "### Plot the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13419360-512f-40eb-9e6a-931a9e04da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    # Plot training loss\n",
    "    # Exclude the first epoch (x=0) by slicing the data, as its a high value that obscures the plot\n",
    "    epochs = range(1, len(history.history['loss']) + 1)\n",
    "    plt.plot(epochs[1:], history.history['loss'][1:], label='Training Loss', linewidth=1.5)\n",
    "    plt.plot(epochs[1:], history.history['val_loss'][1:], label='Validation Loss', linewidth=1.5, linestyle='--')\n",
    "    \n",
    "    #plt.plot(history.history['loss'], label='Training Loss')\n",
    "    #plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # If training loss decreases but validation loss increases, this might indicate overfitting.\n",
    "    # If both losses are high and close, this might indicate and inadequate model (more features?)\n",
    "    # Best result is when both fall over epochs and flatten out, indicating a well trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b8ae16-f8fc-4bfc-8dcd-c5ffceb5a994",
   "metadata": {},
   "source": [
    "### Predictions using  the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78c3fb-4375-4d85-b0cc-168630b70c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# inverse transform the predictions and actual test values\n",
    "y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
    "y_test_rescaled = scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cab8b8-60d0-4910-b17e-3d1fbd81e290",
   "metadata": {},
   "source": [
    "### A test plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3724d-7ce0-450c-91dd-a4a059c78845",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_rescaled, label='Actual')\n",
    "plt.plot(y_pred_rescaled, label='Predicted')\n",
    "plt.legend()\n",
    "plt.title('LSTM Prediction vs Actual Water Levels')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Water Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de5327f-0b50-4e31-b5ab-262b35cd4a78",
   "metadata": {},
   "source": [
    "### forecasting future values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf2d8d-ce7a-49ab-bd64-b2bbc1672140",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_steps = 48 * 6 * days_to_forecast  # 48 steps represents just 4 hours of 5 minute data, *6 for a day\n",
    "\n",
    "timesteps = X.shape[1]\n",
    "\n",
    "# begin at the end\n",
    "last_data = data_scaled[-timesteps:].reshape(1, timesteps, 1)\n",
    "\n",
    "future_predictions = []\n",
    "\n",
    "for _ in range(future_steps):\n",
    "    prediction = model.predict(last_data, verbose=0)\n",
    "    future_predictions.append(prediction[0, 0])\n",
    "    last_data = np.append(last_data[:, 1:, :], prediction.reshape(1, 1, 1), axis=1)\n",
    "\n",
    "# Inverse transform the future predictions\n",
    "future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
    "#print (future_predictions)\n",
    "\n",
    "# Plot the future predictions\n",
    "#plt.figure(figsize=(10, 6))\n",
    "#plt.plot(df.index[-len(y_test_rescaled):], y_test_rescaled, color='blue', label='Actual values')\n",
    "#plt.plot(pd.date_range(df.index[-1], periods=future_steps + 1, freq='5min')[1:], future_predictions, color='green', label='Future Predictions')\n",
    "#plt.title('Future Value Prediction')\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df3335-5733-4af9-bad6-7468e6b06f73",
   "metadata": {},
   "source": [
    "### Revisiting the interactive plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7a208-7143-4bde-a0e0-a5fba59c63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('EA_limited_dataset.csv')\n",
    "\n",
    "createTimeplot  (df, \n",
    "                 show_predicted     = True,\n",
    "                 future_steps       = future_steps,\n",
    "                 future_predictions = future_predictions,\n",
    "                 publishPlot        = False, \n",
    "                 plotName           =\"SharpnessWaterLevelPlot.html\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd7051-b568-420c-b0d5-8b5a75e32956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
